{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c10bb-bfb1-409a-a7a5-e9e669e70f0c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:37:18.682644Z",
     "iopub.status.busy": "2026-01-02T13:37:18.681942Z",
     "iopub.status.idle": "2026-01-02T13:37:19.495068Z",
     "shell.execute_reply": "2026-01-02T13:37:19.494193Z",
     "shell.execute_reply.started": "2026-01-02T13:37:18.682609Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/KL0224/RetrievalPerson -b pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdd7ff-c3d5-4889-b543-1793435cc90a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:37:47.682808Z",
     "iopub.status.busy": "2026-01-02T13:37:47.682110Z",
     "iopub.status.idle": "2026-01-02T13:38:02.351464Z",
     "shell.execute_reply": "2026-01-02T13:38:02.350562Z",
     "shell.execute_reply.started": "2026-01-02T13:37:47.682773Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install open_clip_torch\n",
    "!pip install torchreid\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e3e3c-0ddf-441e-baec-cadc4ee9ac43",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:38:05.441583Z",
     "iopub.status.busy": "2026-01-02T13:38:05.441204Z",
     "iopub.status.idle": "2026-01-02T13:38:05.447770Z",
     "shell.execute_reply": "2026-01-02T13:38:05.447078Z",
     "shell.execute_reply.started": "2026-01-02T13:38:05.441547Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/RetrievalPerson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701f7d7",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:38:10.320645Z",
     "iopub.status.busy": "2026-01-02T13:38:10.320341Z",
     "iopub.status.idle": "2026-01-02T13:38:10.325143Z",
     "shell.execute_reply": "2026-01-02T13:38:10.324587Z",
     "shell.execute_reply.started": "2026-01-02T13:38:10.320620Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "VIDEO_FOLDER = 'videos_test' #'../../input/dataset-person/videos'\n",
    "OUTPUT_FOLDER = 'outputs'\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_FOLDER, 'frames'), exist_ok=True)\n",
    "# os.makedirs(os.path.join(OUTPUT_FOLDER, 'metadata'), exist_ok=True)\n",
    "# os.makedirs(os.path.join(OUTPUT_FOLDER, 'features'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60cb92c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:38:12.685259Z",
     "iopub.status.busy": "2026-01-02T13:38:12.684691Z",
     "iopub.status.idle": "2026-01-02T13:38:43.277017Z",
     "shell.execute_reply": "2026-01-02T13:38:43.276377Z",
     "shell.execute_reply.started": "2026-01-02T13:38:12.685232Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from config import *\n",
    "from tracking.tracklet import TrackletManager\n",
    "from tracking.detector_tracker import run_tracking\n",
    "from sampling.sampler import sample_best_per_window\n",
    "from models.reid import ReIDModel\n",
    "from models.clip_model import CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb6cc9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:38:43.278709Z",
     "iopub.status.busy": "2026-01-02T13:38:43.278446Z",
     "iopub.status.idle": "2026-01-02T13:38:43.283471Z",
     "shell.execute_reply": "2026-01-02T13:38:43.282702Z",
     "shell.execute_reply.started": "2026-01-02T13:38:43.278683Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_image_webp(img_bgr, path: str, quality: int = 80, resize_factor: float = 0.5):\n",
    "    if resize_factor != 1.0:\n",
    "        img_bgr = cv2.resize(img_bgr, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    img_pil.save(path, format=\"WEBP\", quality=quality)\n",
    "\n",
    "def save_crop_webp(crop, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cv2.imwrite(\n",
    "        path,\n",
    "        crop,\n",
    "        [cv2.IMWRITE_WEBP_QUALITY, 100]  # 100 = lossless\n",
    "    )\n",
    "\n",
    "def safe_delete(path):\n",
    "    try:\n",
    "        if path and os.path.exists(path):\n",
    "            os.remove(path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to delete {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c102d4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:38:43.285486Z",
     "iopub.status.busy": "2026-01-02T13:38:43.284614Z",
     "iopub.status.idle": "2026-01-02T13:38:43.298889Z",
     "shell.execute_reply": "2026-01-02T13:38:43.298258Z",
     "shell.execute_reply.started": "2026-01-02T13:38:43.285460Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "manager = TrackletManager()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848d6c4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:39:12.805051Z",
     "iopub.status.busy": "2026-01-02T13:39:12.804722Z",
     "iopub.status.idle": "2026-01-02T13:40:39.597218Z",
     "shell.execute_reply": "2026-01-02T13:40:39.596129Z",
     "shell.execute_reply.started": "2026-01-02T13:39:12.805022Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tracking\n",
    "reid_model = ReIDModel(device=device, model_path='models/osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth')\n",
    "clip_model = CLIPModel(device=device)\n",
    "\n",
    "seqs = sorted(glob.glob(f'{VIDEO_FOLDER}/seq_*'))\n",
    "\n",
    "for seq in seqs[:2]:\n",
    "    seq_name = os.path.basename(seq)\n",
    "    seq_id = int(seq_name.split('_')[-1])\n",
    "    print(f'Processing sequence {seq_name}')\n",
    "    \n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, 'frames', seq_name), exist_ok=True)\n",
    "    cameras = sorted(glob.glob(f'{seq}/camera_*'))\n",
    "    for cam_id, video_path in enumerate(cameras):\n",
    "        manager = TrackletManager()\n",
    "        cam_id += 1\n",
    "        camera_name = \"_\".join(os.path.basename(video_path).split('_')[:2])\n",
    "        camera_frame_folder = os.path.join(OUTPUT_FOLDER, 'frames', seq_name, camera_name)\n",
    "        os.makedirs(camera_frame_folder, exist_ok=True)\n",
    "        print(f'  Processing camera {cam_id}')\n",
    "        for frame_id, frame, boxes, ids, confs in run_tracking(video_path, model_name='yolov8n.pt', \n",
    "                                                               vid_stride=1, \n",
    "                                                               confidence=CONFIDENCE_THRESHOLD,\n",
    "                                                               device=device):\n",
    "            print(f'    Processing frame {frame_id}, detected {len(boxes)} persons') \n",
    "            # detected boxes + (alive but not detected)\n",
    "            print(boxes)\n",
    "            frame_save_path = os.path.join(camera_frame_folder, f'frame_{frame_id:06d}.webp')\n",
    "            save_image_webp(frame, frame_save_path)\n",
    "            for box, tid, conf in zip(boxes, ids, confs):\n",
    "                print(f'      Track ID: {tid}, BBox: {box}, Conf: {conf}')\n",
    "                gid = seq_id*SEQ_ID_OFFSET + cam_id * CAMERA_ID_OFFSET + tid\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "                # invalid box\n",
    "                if x2<=x1 and y2<=y1:\n",
    "                    continue\n",
    "                \n",
    "                crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                crop_path = os.path.join(\n",
    "                    OUTPUT_FOLDER,\n",
    "                    \"crops\",\n",
    "                    seq_name,\n",
    "                    camera_name,\n",
    "                    f\"{gid}_{frame_id:06d}.webp\"\n",
    "                )\n",
    "                \n",
    "                save_crop_webp(crop, crop_path)\n",
    "                t = manager.get(gid, seq_id, cam_id)\n",
    "                t.add_frame(frame_id, box, conf, crop_path)\n",
    "    \n",
    "        tracklets = manager.all()\n",
    "\n",
    "        for t in tracklets:\n",
    "            candidates = sample_best_per_window(t.frames)\n",
    "            # candidates = []\n",
    "            # if len(sampled) <= 3:\n",
    "            #     candidates = sampled\n",
    "            # else:\n",
    "            #     candidates = sampled[:1] + sampled[-1:] + sampled[len(sampled)//2:len(sampled)//2+1]\n",
    "            \n",
    "            candidate_paths = set(f.crop_path for f in candidates)\n",
    "            for f in t.frames:\n",
    "                if f.crop_path not in candidate_paths:\n",
    "                    safe_delete(f.crop_path)\n",
    "                    f.crop_path = None\n",
    "\n",
    "            imgs = [cv2.imread(f.crop_path) for f in candidates]\n",
    "        \n",
    "            reid_feat = reid_model.extract(imgs).mean(axis=0)\n",
    "            reid_feat = reid_feat / np.linalg.norm(reid_feat)\n",
    "\n",
    "            t.reid_embeddings.append(reid_feat)\n",
    "\n",
    "            \n",
    "            clip_feats = clip_model.encode_batch(imgs).mean(axis=0)\n",
    "            clip_feats = clip_feats / np.linalg.norm(clip_feats)\n",
    "            \n",
    "            t.clip_embeddings.append(clip_feats)           \n",
    "        \n",
    "        \n",
    "\n",
    "        # save into metadata.txt\n",
    "        with open(f\"{OUTPUT_FOLDER}/metadata/{seq_name}_{camera_name}.txt\", \"w\") as f:\n",
    "            for t in tracklets:\n",
    "                for frame in t.frames:\n",
    "                    f.write(f\"{t.sequence_id} {t.camera_id} {frame.frame_id} {t.global_id} {int(frame.bbox[0])} {int(frame.bbox[1])} {int(frame.bbox[2])} {int(frame.bbox[3])}\\n\")\n",
    "\n",
    "        # save into features.txt\n",
    "        features = {}\n",
    "        output_path_pkl = f\"{OUTPUT_FOLDER}/features/{seq_name}_{camera_name}.pkl\"\n",
    "        \n",
    "        with open(f\"{OUTPUT_FOLDER}/features/{seq_name}_{camera_name}.txt\", \"w\") as f:\n",
    "            for t in tracklets:\n",
    "                f.write(f\"{t.sequence_id} {t.camera_id} {t.global_id} {t.reid_embeddings[0].tolist()} {t.clip_embeddings[0].tolist()}\\n\")\n",
    "                key = (t.sequence_id, t.camera_id, t.global_id)\n",
    "        \n",
    "                reid_emb = t.reid_embeddings[0]\n",
    "                clip_emb = t.clip_embeddings[0]\n",
    "            \n",
    "                features[key] = [reid_emb, clip_emb]\n",
    "                \n",
    "        with open(output_path_pkl, \"wb\") as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets = manager.all()\n",
    "from collections import defaultdict\n",
    "\n",
    "tracks = defaultdict(list)\n",
    "bbox_per_frame = {}\n",
    "for t in tracklets:\n",
    "    for f in t.frames:\n",
    "        # print(t.global_id, f.frame_id, f.bbox)\n",
    "        # bbox_per_frame.setdefault(f.frame_id, []).append(f.bbox)\n",
    "        tracks[f.frame_id].append({\n",
    "                \"id\": t.global_id,\n",
    "                \"bbox\": f.bbox\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "def visualize_video_with_ids(\n",
    "    video_path,\n",
    "    tracks_per_frame,\n",
    "    output_path=None\n",
    "):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    writer = None\n",
    "    if output_path:\n",
    "        writer = cv2.VideoWriter(\n",
    "            output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "    id_colors = {}\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        for item in tracks_per_frame.get(frame_idx, []):\n",
    "            track_id = item[\"id\"]\n",
    "            x1, y1, x2, y2 = map(int, item[\"bbox\"])\n",
    "\n",
    "            if track_id not in id_colors:\n",
    "                random.seed(int(track_id))\n",
    "                id_colors[track_id] = (\n",
    "                    random.randint(50, 255),\n",
    "                    random.randint(50, 255),\n",
    "                    random.randint(50, 255),\n",
    "                )\n",
    "\n",
    "            color = id_colors[track_id]\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"ID {track_id}\",\n",
    "                (x1, max(0, y1 - 7)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                color,\n",
    "                2\n",
    "            )\n",
    "\n",
    "        if writer:\n",
    "            writer.write(frame)\n",
    "\n",
    "        cv2.imshow(\"Tracking Visualization\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8092d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_video_with_ids('videos_test/seq_001/camera_3_cut.mp4', tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d26741",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:40:48.334460Z",
     "iopub.status.busy": "2026-01-02T13:40:48.333664Z",
     "iopub.status.idle": "2026-01-02T13:40:51.808713Z",
     "shell.execute_reply": "2026-01-02T13:40:51.808082Z",
     "shell.execute_reply.started": "2026-01-02T13:40:48.334424Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sampling + Embeddings\n",
    "reid_model = ReIDModel()\n",
    "\n",
    "for t in manager.all():\n",
    "    sampled = sample_best_per_window(t.frames)\n",
    "    candidates = []\n",
    "    if len(sampled) <= 3:\n",
    "        candidates = sampled\n",
    "    else:\n",
    "        candidates = sampled[:1] + sampled[-1:] + sampled[len(sampled)//2:len(sampled)//2+1]\n",
    "\n",
    "    imgs = [f.image for f in candidates]\n",
    "\n",
    "    reid_feats = reid_model.extract(imgs).mean(axis=0)\n",
    "    t.reid_embeddings.append(reid_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0c5b1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:40:59.255020Z",
     "iopub.status.busy": "2026-01-02T13:40:59.254701Z",
     "iopub.status.idle": "2026-01-02T13:40:59.260707Z",
     "shell.execute_reply": "2026-01-02T13:40:59.260141Z",
     "shell.execute_reply.started": "2026-01-02T13:40:59.254989Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del reid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33e908-f114-4430-98de-3221529c3c48",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea83320",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:41:03.602212Z",
     "iopub.status.busy": "2026-01-02T13:41:03.601891Z",
     "iopub.status.idle": "2026-01-02T13:42:41.619403Z",
     "shell.execute_reply": "2026-01-02T13:42:41.618739Z",
     "shell.execute_reply.started": "2026-01-02T13:41:03.602183Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sampling + Embeddings\n",
    "clip_model = CLIPModel()\n",
    "\n",
    "for t in manager.all():\n",
    "    sampled = sample_best_per_window(t.frames)\n",
    "    candidates = []\n",
    "    if len(sampled) <= 3:\n",
    "        candidates = sampled\n",
    "    else:\n",
    "        candidates = sampled[:1] + sampled[-1:] + sampled[len(sampled)//2:len(sampled)//2+1]\n",
    "\n",
    "    imgs = [f.image for f in candidates]\n",
    "\n",
    "    clip_feats = np.array([clip_model.encode_image(img) for img in imgs]).mean(axis=0)\n",
    "    t.clip_embeddings.append(clip_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd12c4f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:43:29.869659Z",
     "iopub.status.busy": "2026-01-02T13:43:29.869374Z",
     "iopub.status.idle": "2026-01-02T13:43:29.875903Z",
     "shell.execute_reply": "2026-01-02T13:43:29.874974Z",
     "shell.execute_reply.started": "2026-01-02T13:43:29.869634Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del clip_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac5a2c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-02T13:43:41.758264Z",
     "iopub.status.busy": "2026-01-02T13:43:41.757539Z",
     "iopub.status.idle": "2026-01-02T13:43:41.778230Z",
     "shell.execute_reply": "2026-01-02T13:43:41.777543Z",
     "shell.execute_reply.started": "2026-01-02T13:43:41.758232Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tracklets = manager.all()\n",
    "\n",
    "# save into metadata.txt\n",
    "with open(f\"{OUTPUT_FOLDER}/metadata.txt\", \"a\") as f:\n",
    "    for t in tracklets:\n",
    "        for frame in t.frames:\n",
    "            f.write(f\"{t.sequence_id} {t.camera_id} {frame.frame_id} {t.global_id} {int(frame.bbox[0])} {int(frame.bbox[1])} {int(frame.bbox[2])} {int(frame.bbox[3])}\\n\")\n",
    "\n",
    "# save into features.txt\n",
    "with open(f\"{OUTPUT_FOLDER}/features.txt\", \"w\") as f:\n",
    "    for t in tracklets:\n",
    "        f.write(f\"{t.sequence_id} {t.camera_id} {t.global_id} {t.reid_embeddings[0].tolist()} {t.clip_embeddings[0].tolist()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61786a-de8d-4d93-98fc-e84604ba0a1b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r results.zip /kaggle/working/outputs\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'results.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8665047,
     "sourceId": 13632798,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
